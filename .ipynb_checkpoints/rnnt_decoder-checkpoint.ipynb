{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o/ 근데 칠십 퍼센트가 커 보이긴 하는데 이백 벌다 백 사십 벌면 빡셀걸? b/\n",
      "근데 삼 학년 때 까지는 국가장학금 바+ 받으면서 다녔던 건가?\n"
     ]
    }
   ],
   "source": [
    "test1 = \"o/ 근데 (70%)/(칠십 퍼센트)가 커 보이긴 하는데 (200)/(이백) 벌다 (140)/(백 사십) 벌면 빡셀걸? b/\"\n",
    "test2 = \"근데 (3학년)/(삼 학년) 때 까지는 국가장학금 바+ 받으면서 다녔던 건가?\"\n",
    "\n",
    "def bracket_filter(sentence):\n",
    "  new_sentence = str()\n",
    "  flag = False\n",
    "  \n",
    "  for ch in sentence:\n",
    "    if ch == '(' and flag == False:\n",
    "      flag = True\n",
    "      continue\n",
    "    if ch == '(' and flag == True:\n",
    "      flag = False\n",
    "      continue\n",
    "    if ch != ')' and flag == False:\n",
    "      new_sentence += ch\n",
    "  return new_sentence\n",
    "\n",
    "print(bracket_filter(test1))\n",
    "print(bracket_filter(test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "근데 칠십 퍼센트가 커 보이긴 하는데 이백 벌다 백 사십 벌면 빡셀걸?\n",
      "c샾 배워봤어?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test1 = \"o/ 근데 칠십 퍼센트가 커 보이긴 하는데 이백 벌다 백 사십 벌면 빡셀걸? b/\"\n",
    "test2 = \"c# 배워봤어?\"\n",
    "\n",
    "def special_filter(sentence):\n",
    "  SENTENCE_MARK = ['?', '!']\n",
    "  NOISE = ['o', 'n', 'u', 'b', 'l']\n",
    "  EXCEPT = ['/', '+', '*', '-', '@', '$', '^', '&', '[', ']', '=', ':', ';', '.', ',']\n",
    "  \n",
    "  new_sentence = str()\n",
    "  for idx, ch in enumerate(sentence):\n",
    "    if ch not in SENTENCE_MARK:\n",
    "      # o/, n/ 등 처리\n",
    "      if idx + 1 < len(sentence) and ch in NOISE and sentence[idx+1] == '/': \n",
    "        continue \n",
    "\n",
    "    if ch == '#': \n",
    "      new_sentence += '샾'\n",
    "\n",
    "    elif ch not in EXCEPT: \n",
    "      new_sentence += ch\n",
    "\n",
    "  pattern = re.compile(r'\\s\\s+')\n",
    "  new_sentence = re.sub(pattern, ' ', new_sentence.strip())\n",
    "  return new_sentence\n",
    "\n",
    "print(special_filter(test1))\n",
    "print(special_filter(test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 나 쓰리 DS 갖고 싶다 쓰리 DS\n"
     ]
    }
   ],
   "source": [
    "# test = \"o/ 근데 (70%)/(칠십 퍼센트)가 커 보이긴 하는데 (200)/(이백) 벌다 (140)/(백 사십) 벌면 빡셀걸? b/\"\n",
    "test = 'b/ 아 나 (3DS)/(쓰리 DS) 갖고 싶다. (3DS)/(쓰리 DS)'\n",
    "\n",
    "def sentence_filter(raw_sentence):\n",
    "  return special_filter(bracket_filter(raw_sentence))\n",
    "\n",
    "print(sentence_filter(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosung = (\"ㄱ\", \"ㄲ\", \"ㄴ\", \"ㄷ\", \"ㄸ\", \"ㄹ\", \"ㅁ\", \"ㅂ\", \"ㅃ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅉ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\")\n",
    "\n",
    "jungsung = (\"ㅏ\", \"ㅐ\", \"ㅑ\", \"ㅒ\", \"ㅓ\", \"ㅔ\", \"ㅕ\", \"ㅖ\", \"ㅗ\", \"ㅘ\", \"ㅙ\", \"ㅚ\", \"ㅛ\", \"ㅜ\", \"ㅝ\", \"ㅞ\", \"ㅟ\", \"ㅠ\", \"ㅡ\", \"ㅢ\", \"ㅣ\")\n",
    "\n",
    "jongsung = (\"\", \"ㄱ\", \"ㄲ\", \"ㄳ\", \"ㄴ\", \"ㄵ\", \"ㄶ\", \"ㄷ\", \"ㄹ\", \"ㄺ\", \"ㄻ\", \"ㄼ\", \"ㄽ\", \"ㄾ\", \"ㄿ\", \"ㅀ\", \"ㅁ\", \"ㅂ\", \"ㅄ\", \"ㅅ\", \"ㅆ\", \"ㅇ\", \"ㅈ\", \"ㅊ\", \"ㅋ\", \"ㅌ\", \"ㅍ\", \"ㅎ\")\n",
    "\n",
    "def isHangeul(one_character):\n",
    "    return 0xAC00 <= ord(one_character[:1]) <= 0xD7A3\n",
    "\n",
    "def hangeulExplode(one_hangeul):\n",
    "    a = one_hangeul[:1]\n",
    "    if isHangeul(a) != True:\n",
    "        return False\n",
    "    b = ord(a) - 0xAC00\n",
    "    cho = b // (21*28)\n",
    "    jung = b % (21*28) // 28\n",
    "    jong = b % 28\n",
    "    if jong == 0:\n",
    "        return (chosung[cho], jungsung[jung])\n",
    "    else:\n",
    "        return (chosung[cho], jungsung[jung], jongsung[jong])\n",
    "\n",
    "def hangeulJoin(inputlist):\n",
    "    result = \"\"\n",
    "    cho, jung, jong = 0, 0, 0\n",
    "    inputlist.insert(0, \"\")\n",
    "    while len(inputlist) > 1:\n",
    "        if inputlist[-1] in jongsung:\n",
    "            if inputlist[-2] in jungsung:\n",
    "                jong = jongsung.index(inputlist.pop())\n",
    "            \n",
    "            else:\n",
    "                result += inputlist.pop()\n",
    "        elif inputlist[-1] in jungsung:\n",
    "            if inputlist[-2] in chosung:\n",
    "                jung = jungsung.index(inputlist.pop())\n",
    "                cho = chosung.index(inputlist.pop())\n",
    "                result += chr(0xAC00 + ((cho*21)+jung)*28+jong)\n",
    "                cho, jung, jong = 0, 0, 0\n",
    "            else:\n",
    "                result += inputlist.pop()\n",
    "\n",
    "        else:\n",
    "            result += inputlist.pop()\n",
    "    else:\n",
    "        return result[::-1]\n",
    "\n",
    "def pureosseugi(inputtext):\n",
    "    result = \"\"\n",
    "    for i in inputtext:\n",
    "        if isHangeul(i) == True:\n",
    "            for j in hangeulExplode(i):\n",
    "                result += j\n",
    "        else:\n",
    "            result += i\n",
    "    \n",
    "    return result\n",
    "\n",
    "def moasseugi(inputtext):\n",
    "    t1 = []\n",
    "    for i in inputtext:\n",
    "        t1.append(i)\n",
    "\n",
    "    return hangeulJoin(t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "class Phoneme:\n",
    "  def __init__ (self):\n",
    "    self.BLANK_INDEX = 0\n",
    "    self.START_INDEX = 1\n",
    "    self.END_INDEX = 2\n",
    "    self.SPACE_INDEX = 3\n",
    "    self.OOV_INDEX = 4\n",
    "\n",
    "class PhonemeGenerator (Phoneme):\n",
    "  def __init__ (self, labels):\n",
    "    super(PhonemeGenerator, self).__init__()\n",
    "    self.phonemes = ['<BLANK>', '<START>', '<END>', ' ']\n",
    "\n",
    "    texts = []\n",
    "    for label in labels:\n",
    "      for phoneme in label:\n",
    "        if not isHangeul(phoneme) and not phoneme == ' ' and not phoneme == '?':\n",
    "          break\n",
    "        for pure in pureosseugi(phoneme):\n",
    "          texts.append(pure)\n",
    "\n",
    "    tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    for i in range(1, len(tokenizer.index_word) + 1):\n",
    "      self.phonemes.append(tokenizer.index_word[i])\n",
    "\n",
    "    self.phoneme_index = {}\n",
    "    for i, phoneme in enumerate(self.phonemes):\n",
    "      self.phoneme_index[phoneme] = i\n",
    "    \n",
    "    self.VOCAB_SIZE = len(self.phonemes)\n",
    "  \n",
    "  def save (self, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "      pickle.dump((self.phonemes, self.phoneme_index), f)\n",
    "\n",
    "\n",
    "class PhonemeLoader (Phoneme):\n",
    "  def __init__ (self, filename):\n",
    "    super(PhonemeLoader, self).__init__()\n",
    "    with open(filename, 'rb') as f:\n",
    "      self.phonemes, self.phoneme_index = pickle.load(f)\n",
    "\n",
    "    self.VOCAB_SIZE = len(self.phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "class Dataset:\n",
    "  def get_data (self, idx):\n",
    "    return (\n",
    "      self.extract_spectrogram(self.file_phoneme_vector_pairs[idx][0]),\n",
    "      [0] + self.file_phoneme_vector_pairs[idx][1]\n",
    "    )\n",
    "  \n",
    "  def get_len (self):\n",
    "    return len(self.file_phoneme_vector_pairs)\n",
    "\n",
    "  def extract_spectrogram (self, filename):\n",
    "    waveform = np.memmap(filename, dtype='h', mode='r')\n",
    "\n",
    "    sr = 16000\n",
    "    st = 1 / sr\n",
    "\n",
    "    t = np.linspace(0, waveform.shape[0] * st, waveform.shape[0])\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=np.float32(waveform), n_fft=512, hop_length=256, window='hamming', sr=sr, n_mels=128)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    log_S = np.transpose(log_S)\n",
    "\n",
    "    return log_S\n",
    "\n",
    "class RandomDataset (Dataset):\n",
    "  def __init__ (self):\n",
    "    super(RandomDataset, self).__init__()\n",
    "    with open('./ko-audio-dataset/sentence-script/KsponSpeech_scripts/train.trn', 'r', encoding='utf-8') as file:\n",
    "      lines = file.readlines()\n",
    "    def process_line (line):\n",
    "      line = line.split(' :: ')\n",
    "      line[0] = os.path.join('./ko-audio-dataset/audio/', line[0])\n",
    "      line[1] = sentence_filter(line[1])\n",
    "      return line\n",
    "    file_label_pairs = list(map(process_line, lines))\n",
    "    file_label_pairs = list(filter(lambda pair: not self.check_skip_label(pair[1]), file_label_pairs))\n",
    "    self.phoneme = PhonemeGenerator([label for file, label in file_label_pairs])\n",
    "    file_phoneme_pairs = list(map(lambda pair: (pair[0], pureosseugi(pair[1])), file_label_pairs))\n",
    "    self.file_phoneme_vector_pairs = [[pair[0], [self.phoneme.phoneme_index[phoneme] for phoneme in pair[1]]] for pair in file_phoneme_pairs]\n",
    "    random.shuffle(self.file_phoneme_vector_pairs)\n",
    "  \n",
    "  def save (self, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "      pickle.dump((self.phoneme, self.file_phoneme_vector_pairs), f)\n",
    "  \n",
    "  def check_skip_hangul (self, hangul):\n",
    "    return not isHangeul(hangul) and not hangul == ' ' and not hangul == '?'\n",
    "\n",
    "  def check_skip_label (self, label):\n",
    "    for hangul in label:\n",
    "      if self.check_skip_hangul(hangul):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class DatasetLoader (Dataset):\n",
    "  def __init__ (self, filename):\n",
    "    super(DatasetLoader, self).__init__()\n",
    "    with open(filename, 'rb') as f:\n",
    "      self.phoneme, self.file_phoneme_vector_pairs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSizeLimitingIterator:\n",
    "  def __init__ (self, dataset, limit, idx):\n",
    "    self.dataset = dataset\n",
    "    self.limit = limit\n",
    "    self.idx = idx\n",
    "    while self.idx < self.dataset.get_len():\n",
    "      data = self.dataset.get_data(self.idx)\n",
    "      if data[0].shape[0] * len(data[1]) * len(self.dataset.phoneme.phonemes) <= self.limit:\n",
    "        break\n",
    "      self.idx += 1\n",
    "\n",
    "  def next (self):\n",
    "    idx = self.idx + 1\n",
    "    while idx < self.dataset.get_len():\n",
    "      data = self.dataset.get_data(idx)\n",
    "      if data[0].shape[0] * len(data[1]) * len(self.dataset.phoneme.phonemes) <= self.limit:\n",
    "        break\n",
    "      idx += 1\n",
    "    return DatasetSizeLimitingIterator(self.dataset, self.limit, idx)\n",
    "  \n",
    "  def check_end (self):\n",
    "    return self.idx >= self.dataset.get_len()\n",
    "\n",
    "  def get_value (self):\n",
    "    return self.dataset.get_data(self.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetStepExtractor:\n",
    "  def __init__ (self, dataset, step_size, iterator):\n",
    "    self.dataset = dataset\n",
    "    self.step_size = step_size\n",
    "    self.value = []\n",
    "    while not iterator.check_end() and len(self.value) < self.step_size:\n",
    "      self.value.append(iterator.get_value())\n",
    "      iterator = iterator.next()\n",
    "    self.is_end = len(self.value) < self.step_size\n",
    "    self.next_iterator = iterator\n",
    "  \n",
    "  def check_end (self):\n",
    "    return self.is_end\n",
    "  \n",
    "  def get_value (self):\n",
    "    return self.value\n",
    "  \n",
    "  def get_next_extractor (self):\n",
    "    return DatasetStepExtractor(self.dataset, self.step_size, self.next_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder (tf.keras.Model):\n",
    "  def __init__ (self, units, output_dim):\n",
    "    super(Encoder, self).__init__(self)\n",
    "    self.gru = tf.keras.layers.GRU(units, recurrent_initializer='glorot_uniform', return_sequences=True, return_state=True)\n",
    "    self.fc = tf.keras.layers.Dense(output_dim)\n",
    "    \n",
    "  def call (self, inputs):\n",
    "    rnn_outputs, hidden_states = self.gru(inputs)\n",
    "    outputs = self.fc(rnn_outputs)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder (tf.keras.Model):\n",
    "  def __init__ (self, vocab_size, embedding_dim, units, output_dim):\n",
    "    super(Decoder, self).__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(units, recurrent_initializer='glorot_uniform', return_sequences=True, return_state=True)\n",
    "    self.fc = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "  def call (self, inputs):\n",
    "    embedded = self.embedding(inputs)\n",
    "    outputs, hidden_states = self.gru(embedded)\n",
    "    outputs = self.fc(outputs)\n",
    "    return outputs, hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointNet (tf.keras.Model):\n",
    "  def __init__ (self, inner_dim, vocab_size):\n",
    "    super(JointNet, self).__init__()\n",
    "    self.forward_layer = tf.keras.layers.Dense(inner_dim, activation='tanh')\n",
    "    self.project_layer = tf.keras.layers.Dense(vocab_size)\n",
    "  \n",
    "  def call (self, inputs):\n",
    "    enc_outputs, dec_outputs = inputs\n",
    "    joint_inputs = tf.expand_dims(enc_outputs, axis=2) + tf.expand_dims(dec_outputs, axis=1)\n",
    "    outputs = self.forward_layer(joint_inputs)\n",
    "    outputs = self.project_layer(outputs)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer (tf.keras.Model):\n",
    "  def __init__ (self, encoder, decoder, joint_net):\n",
    "    super(Transducer, self).__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.joint_net = joint_net\n",
    "\n",
    "  def __init__ (self, embedding_dim, units, coder_output_dim, joint_net_inner_dim, vocab_size):\n",
    "    super(Transducer, self).__init__()\n",
    "    self.encoder = Encoder(units, coder_output_dim)\n",
    "    self.decoder = Decoder(vocab_size, embedding_dim, units, coder_output_dim)\n",
    "    self.joint_net = JointNet(joint_net_inner_dim, vocab_size)\n",
    "    self.vocab_size = vocab_size\n",
    "  \n",
    "  def call (self, inputs):\n",
    "    enc_inputs, dec_inputs = inputs\n",
    "    enc_outputs = self.encoder(enc_inputs)\n",
    "    dec_outputs, dec_states = self.decoder(dec_inputs)\n",
    "    outputs = self.joint_net([enc_outputs, dec_outputs])\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDecoder:\n",
    "  def __init__ (self, transducer):\n",
    "    self.transducer = transducer\n",
    "  \n",
    "  def decode (self, spectrogram):\n",
    "    label = [0]\n",
    "    for i in range(spectrogram.shape[0]):\n",
    "      sub_spectrogram = spectrogram[0: i + 1]\n",
    "      sub_spectrogram = tf.convert_to_tensor(sub_spectrogram)\n",
    "      sub_spectrogram = tf.expand_dims(sub_spectrogram, axis=0)\n",
    "      sub_label = tf.constant([label], dtype=tf.int32)\n",
    "      sub_rst = self.transducer((sub_spectrogram, sub_label))\n",
    "      sub_rst = tf.argmax(sub_rst[0][-1][-1], axis=-1).numpy()\n",
    "      label.append(sub_rst)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = dataset.phoneme.VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "UNITS = 1024\n",
    "CODER_OUTPUT_DIM = 512\n",
    "JOINT_NET_INNER_DIM = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transducer = Transducer(EMBEDDING_DIM, UNITS, CODER_OUTPUT_DIM, JOINT_NET_INNER_DIM, VOCAB_SIZE)\n",
    "transducer.load_weights('./checkpoints/no40000/ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AudioDecoder(transducer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = decoder.decode(extractor.get_value()[0][0])\n",
    "ret = []\n",
    "for i in rst:\n",
    "  ret.append(dataset.phoneme.phonemes[i])\n",
    "\n",
    "print(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = extractor.get_next_extractor()\n",
    "extractor = extractor.get_next_extractor()\n",
    "extractor = extractor.get_next_extractor()\n",
    "spectrogram, labels = extractor.get_value()[0]\n",
    "\n",
    "logits = transducer((tf.convert_to_tensor([spectrogram]), tf.convert_to_tensor([labels])))\n",
    "print(tf.argmax(logits, axis=-1)[:, -30: , 0: ])\n",
    "# print(logits[:, -30: , 0: ,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec62f2ec7c7d49224ec335e3ef472b8ef537dc7949933ed74784e8710c2a92fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
